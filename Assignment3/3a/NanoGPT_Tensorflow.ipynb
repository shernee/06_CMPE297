{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shernee/06_CMPE297/blob/main/NanoGPT_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "x9t529IT580a"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0EBlU4qvrlG",
        "outputId": "ceb23113-ecf3-4746-db47-49b5842433e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "block_size = 32\n",
        "max_iters = 1000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "eval_iters = 10\n",
        "n_embd = 64\n",
        "n_head = 8\n",
        "n_layer = 8"
      ],
      "metadata": {
        "id": "DeADGpnw6C9j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_file_path = \"/content/drive/MyDrive/297_data/Sorcerer's_stone.txt\""
      ],
      "metadata": {
        "id": "Mz6j011Rvxeg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset:\n",
        "  def __init__(self):\n",
        "    self.vocab_size = 0\n",
        "    self.train_data = tf.constant([], dtype=tf.int32)\n",
        "    self.val_data = tf.constant([], dtype=tf.int32)\n",
        "\n",
        "  def read_dataset(self):\n",
        "    with tf.io.gfile.GFile(input_file_path, 'r') as f:\n",
        "        self.data = f.read()\n",
        "\n",
        "  def prepare_dataset(self):\n",
        "    chars = sorted(list(set(self.data)))\n",
        "    self.vocab_size = len(chars)\n",
        "    char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
        "    int_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "    self.encode = lambda s: [char_to_int[c] for c in s]\n",
        "    self.decode = lambda l: ''.join([int_to_char[i] for i in l])\n",
        "\n",
        "  def data_split(self):\n",
        "    data_tensor = tf.convert_to_tensor(self.encode(self.data), dtype=tf.int32)\n",
        "    n = int(0.8 * len(data_tensor))\n",
        "    self.train_data = data_tensor[:n]\n",
        "    self.val_data = data_tensor[n:]\n",
        "\n",
        "  def get_batch(self, split):\n",
        "    data = self.train_data if split == 'train' else self.val_data\n",
        "    data_length = tf.shape(data)[0]\n",
        "\n",
        "    ix = tf.random.uniform([batch_size], minval=0, maxval=data_length - block_size, dtype=tf.int32)\n",
        "\n",
        "    start_indices = tf.expand_dims(ix, -1)\n",
        "    range_indices = tf.range(block_size, dtype=tf.int32)\n",
        "    indices = start_indices + range_indices\n",
        "\n",
        "    x = tf.gather(data, indices)\n",
        "\n",
        "    y_indices = start_indices + 1 + range_indices\n",
        "    y = tf.gather(data, y_indices)\n",
        "\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "rrd7yijpOcIZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Loss:\n",
        "  def estimate_loss(self):\n",
        "    out = {}\n",
        "    for split in ['train', 'val']:\n",
        "      total_loss = tf.zeros([])\n",
        "      for k in range(eval_iters):\n",
        "          X, Y = datasetObj.get_batch(split)\n",
        "          _, loss = model(X, Y)\n",
        "          total_loss += loss\n",
        "      out[split] = total_loss / eval_iters\n",
        "    return out\n",
        "\n",
        "lossObj = Loss()"
      ],
      "metadata": {
        "id": "kYGFSWWJRqfb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionHead(tf.keras.layers.Layer):\n",
        "  def __init__(self, head_size, n_embd, block_size):\n",
        "    super(AttentionHead, self).__init__()\n",
        "    self.key = tf.keras.layers.Dense(head_size, use_bias=False, input_shape=(n_embd,))\n",
        "    self.query = tf.keras.layers.Dense(head_size, use_bias=False, input_shape=(n_embd,))\n",
        "    self.value = tf.keras.layers.Dense(head_size, use_bias=False, input_shape=(n_embd,))\n",
        "    self.tril = tf.linalg.band_part(tf.ones((block_size, block_size)), -1, 0)\n",
        "\n",
        "  def call(self, x):\n",
        "    B, T, C = x.shape\n",
        "    k = self.key(x)\n",
        "    q = self.query(x)\n",
        "    w = tf.matmul(q, k, transpose_b=True) * C**-0.5\n",
        "    w = tf.where(self.tril[:T, :T] == 0, float('-inf'), w)\n",
        "    w = tf.nn.softmax(w, axis=-1)\n",
        "\n",
        "    v = self.value(x)\n",
        "    out = tf.matmul(w, v)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "bTVi1D-uSKQT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_heads, head_size, n_embd, block_size):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.heads = [AttentionHead(head_size, n_embd, block_size) for _ in range(num_heads)]\n",
        "    self.proj = tf.keras.layers.Dense(n_embd)\n",
        "\n",
        "  def call(self, x):\n",
        "    out = tf.concat([h(x) for h in self.heads], axis=-1)\n",
        "    return self.proj(out)"
      ],
      "metadata": {
        "id": "IPrnCUFiUCB5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, n_embd):\n",
        "    super(FeedForward, self).__init__()\n",
        "    self.net = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(4 * n_embd),\n",
        "        tf.keras.layers.ReLU(),\n",
        "        tf.keras.layers.Dense(n_embd)\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "PMABKHfSUJX6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "  def __init__(self, n_embd, n_head, block_size):\n",
        "    super(TransformerBlock, self).__init__()\n",
        "    head_size = n_embd // n_head\n",
        "    self.sa = MultiHeadAttention(n_head, head_size, n_embd, block_size)\n",
        "    self.ffwd = FeedForward(n_embd)\n",
        "    self.ln1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.ln2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = x + self.sa(self.ln1(x))\n",
        "    x = x + self.ffwd(self.ln2(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "aV8Trt7HUVkE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NanoGPT(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(NanoGPT, self).__init__()\n",
        "    self.token_embedding_table = tf.keras.layers.Embedding(datasetObj.vocab_size, n_embd)\n",
        "    self.position_embedding_table = tf.keras.layers.Embedding(block_size, n_embd)\n",
        "    self.blocks = tf.keras.Sequential([TransformerBlock(n_embd, n_head, block_size) for _ in range(n_layer)])\n",
        "    self.ln_f = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.lm_head = tf.keras.layers.Dense(datasetObj.vocab_size)\n",
        "\n",
        "  def call(self, idx, targets=None, training=False):\n",
        "    shape = tf.shape(idx)\n",
        "    B = shape[0]\n",
        "    T = shape[1]\n",
        "    tok_emb = self.token_embedding_table(idx)\n",
        "    pos_emb = self.position_embedding_table(tf.range(T))\n",
        "    x = tok_emb + pos_emb\n",
        "    x = self.blocks(x)\n",
        "    x = self.ln_f(x)\n",
        "    logits = self.lm_head(x)\n",
        "\n",
        "    if targets is None:\n",
        "        loss = None\n",
        "    else:\n",
        "        loss = tf.keras.losses.sparse_categorical_crossentropy(targets, logits, from_logits=True)\n",
        "        loss = tf.reduce_mean(loss)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens, batch_size=4):\n",
        "    for _ in range(max_new_tokens):\n",
        "      idx_cond = idx[:, -block_size:]\n",
        "      logits, _ = self(idx_cond)\n",
        "      logits = logits[:, -1, :]\n",
        "\n",
        "      idx_next = tf.random.categorical(logits, num_samples=batch_size, dtype=tf.int32)\n",
        "\n",
        "      idx = tf.concat([idx, idx_next], axis=1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "6wlMV8JYUjiL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generateNext():\n",
        "  context = tf.zeros((1, 1), dtype=tf.int32)\n",
        "  generated_seq = model.generate(context, max_new_tokens=500)\n",
        "  print(datasetObj.decode(generated_seq[0].numpy()))"
      ],
      "metadata": {
        "id": "dyCbV9XLWH5q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TozLG9XW53XR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75dba6dd-49e0-4f31-8cde-7ff0c752789c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration =  0\n",
            "step 0: train loss 4.6827, val loss 4.6474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7ce9b0197d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7ce9b0197d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration =  1\n",
            "Iteration =  2\n",
            "Iteration =  3\n",
            "Iteration =  4\n",
            "Iteration =  5\n",
            "Iteration =  6\n",
            "Iteration =  7\n",
            "Iteration =  8\n",
            "Iteration =  9\n",
            "Iteration =  10\n",
            "Iteration =  11\n",
            "Iteration =  12\n",
            "Iteration =  13\n",
            "Iteration =  14\n",
            "Iteration =  15\n",
            "Iteration =  16\n",
            "Iteration =  17\n",
            "Iteration =  18\n",
            "Iteration =  19\n",
            "Iteration =  20\n",
            "Iteration =  21\n",
            "Iteration =  22\n",
            "Iteration =  23\n",
            "Iteration =  24\n",
            "Iteration =  25\n",
            "Iteration =  26\n",
            "Iteration =  27\n",
            "Iteration =  28\n",
            "Iteration =  29\n",
            "Iteration =  30\n",
            "Iteration =  31\n",
            "Iteration =  32\n",
            "Iteration =  33\n",
            "Iteration =  34\n",
            "Iteration =  35\n",
            "Iteration =  36\n",
            "Iteration =  37\n",
            "Iteration =  38\n",
            "Iteration =  39\n",
            "Iteration =  40\n",
            "Iteration =  41\n",
            "Iteration =  42\n",
            "Iteration =  43\n",
            "Iteration =  44\n",
            "Iteration =  45\n",
            "Iteration =  46\n",
            "Iteration =  47\n",
            "Iteration =  48\n",
            "Iteration =  49\n",
            "Iteration =  50\n",
            "Iteration =  51\n",
            "Iteration =  52\n",
            "Iteration =  53\n",
            "Iteration =  54\n",
            "Iteration =  55\n",
            "Iteration =  56\n",
            "Iteration =  57\n",
            "Iteration =  58\n",
            "Iteration =  59\n",
            "Iteration =  60\n",
            "Iteration =  61\n",
            "Iteration =  62\n",
            "Iteration =  63\n",
            "Iteration =  64\n",
            "Iteration =  65\n",
            "Iteration =  66\n",
            "Iteration =  67\n",
            "Iteration =  68\n",
            "Iteration =  69\n",
            "Iteration =  70\n",
            "Iteration =  71\n",
            "Iteration =  72\n",
            "Iteration =  73\n",
            "Iteration =  74\n",
            "Iteration =  75\n",
            "Iteration =  76\n",
            "Iteration =  77\n",
            "Iteration =  78\n",
            "Iteration =  79\n",
            "Iteration =  80\n",
            "Iteration =  81\n",
            "Iteration =  82\n",
            "Iteration =  83\n",
            "Iteration =  84\n",
            "Iteration =  85\n",
            "Iteration =  86\n",
            "Iteration =  87\n",
            "Iteration =  88\n",
            "Iteration =  89\n",
            "Iteration =  90\n",
            "Iteration =  91\n",
            "Iteration =  92\n",
            "Iteration =  93\n",
            "Iteration =  94\n",
            "Iteration =  95\n",
            "Iteration =  96\n",
            "Iteration =  97\n",
            "Iteration =  98\n",
            "Iteration =  99\n",
            "Iteration =  100\n",
            "step 100: train loss 2.7730, val loss 2.7862\n",
            "Iteration =  101\n",
            "Iteration =  102\n",
            "Iteration =  103\n",
            "Iteration =  104\n",
            "Iteration =  105\n",
            "Iteration =  106\n",
            "Iteration =  107\n",
            "Iteration =  108\n",
            "Iteration =  109\n",
            "Iteration =  110\n",
            "Iteration =  111\n",
            "Iteration =  112\n",
            "Iteration =  113\n",
            "Iteration =  114\n",
            "Iteration =  115\n",
            "Iteration =  116\n",
            "Iteration =  117\n",
            "Iteration =  118\n",
            "Iteration =  119\n",
            "Iteration =  120\n",
            "Iteration =  121\n",
            "Iteration =  122\n",
            "Iteration =  123\n",
            "Iteration =  124\n",
            "Iteration =  125\n",
            "Iteration =  126\n",
            "Iteration =  127\n",
            "Iteration =  128\n",
            "Iteration =  129\n",
            "Iteration =  130\n",
            "Iteration =  131\n",
            "Iteration =  132\n",
            "Iteration =  133\n",
            "Iteration =  134\n",
            "Iteration =  135\n",
            "Iteration =  136\n",
            "Iteration =  137\n",
            "Iteration =  138\n",
            "Iteration =  139\n",
            "Iteration =  140\n",
            "Iteration =  141\n",
            "Iteration =  142\n",
            "Iteration =  143\n",
            "Iteration =  144\n",
            "Iteration =  145\n",
            "Iteration =  146\n",
            "Iteration =  147\n",
            "Iteration =  148\n",
            "Iteration =  149\n",
            "Iteration =  150\n",
            "Iteration =  151\n",
            "Iteration =  152\n",
            "Iteration =  153\n",
            "Iteration =  154\n",
            "Iteration =  155\n",
            "Iteration =  156\n",
            "Iteration =  157\n",
            "Iteration =  158\n",
            "Iteration =  159\n",
            "Iteration =  160\n",
            "Iteration =  161\n",
            "Iteration =  162\n",
            "Iteration =  163\n",
            "Iteration =  164\n",
            "Iteration =  165\n",
            "Iteration =  166\n",
            "Iteration =  167\n",
            "Iteration =  168\n",
            "Iteration =  169\n",
            "Iteration =  170\n",
            "Iteration =  171\n",
            "Iteration =  172\n",
            "Iteration =  173\n",
            "Iteration =  174\n",
            "Iteration =  175\n",
            "Iteration =  176\n",
            "Iteration =  177\n",
            "Iteration =  178\n",
            "Iteration =  179\n",
            "Iteration =  180\n",
            "Iteration =  181\n",
            "Iteration =  182\n",
            "Iteration =  183\n",
            "Iteration =  184\n",
            "Iteration =  185\n",
            "Iteration =  186\n",
            "Iteration =  187\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "  datasetObj = Dataset()\n",
        "  datasetObj.read_dataset()\n",
        "  datasetObj.prepare_dataset()\n",
        "  datasetObj.data_split()\n",
        "\n",
        "  model = NanoGPT()\n",
        "\n",
        "  optimizer = tf.keras.optimizers.AdamW(learning_rate=learning_rate)\n",
        "\n",
        "  for iter in range(max_iters):\n",
        "    print(\"Iteration = \", iter)\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "      losses = lossObj.estimate_loss()\n",
        "      print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    xb, yb = datasetObj.get_batch('train')\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        _, loss = model(xb, yb)\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generateNext()"
      ],
      "metadata": {
        "id": "6oEiOyZyWNGx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc2f625-ab37-4e31-959c-398a8139fedd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " WNLioiannns sat ieurlnneee taste e htib.lll\n",
            "  iftpleiee.dndeia hYfh,iearlns  . I  Wihaaddns  aev  faliaennnieee :drryien,serls. \n",
            " \n",
            "\n",
            "\n",
            "N\n",
            "\n",
            "   TtfAfrrryiaa nsnaeie.  diaeordfn , etvsweeainnnnei emvsveyaed dstuoth h lomf f'frlteh  siaaonnnneoeind rooeasn thhhovua nfshoee.    btAillel  f raas.ets  tedtrn, y arbseait    atSiltrlaieedrslea yooaatnyd e, yciwn ehieaudr.d   .    A]GVaaoordnleeea lnreiaimsnn.ti JLtSothy    yhftore lwfwaaeortrrii  hhwissge,rdd    ohmwiaaa,lsn  iedpf ahtt e itnnn eeersdne ichhhhea efdas is.\n",
            "  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "   I  'thooh, ,eei  Denne iisnfsfcat.lc BNwSmaaasnnina,naoi htamse eaxtfaeae, nneoiesp groari 'sbsilyepf t allsnieied'nd e  hiass   tibth.rceoeurrl.\n",
            " \n",
            " YWIM aoolnvneie bcht eeewsnd e,\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Y Joooa t  dwah    qbLmouae ,  bftaslgneaeindnnoiionnnnaeeednlsse .    itShaeoes]  walSepuchryouuaveeee,ldr  iene veeeh  itnh-noiioonsn.inowwtwoieelrr,    stfAlren  t nhbmeooowddnt o,    tahWilie dx hfag  aem ntoauokndlh  emnnpees rgtizneki,e,    JaBI    wLttarrreeoe   effcveeeetrnt .e TI\n",
            "I l' msRwe aannttli  nbtweooe d rayei  nniooolsdki i tttt e  ctwtreaawlsreyeeasr totbee exvaainl tPVbloeadrrneyo,    soCheaae d  obthoeee   riaaarnrniiyinsnss .tiohh s  fiat l, mwvurriw.a shtaaljkr  eisttny eenyss,e,,    ebeI l  Rottihhodrwwioo,    tawbilele  laoookm, aS Thhiatsslaio sawhieied, doyia rnrouooknns    armlaoeas,nnaeyi hn. \n",
            "  AhSI    sTmseiiadntte e wsyinlnnioeedc? A\n",
            "I tcomleeatnnreeyed nstoaadnnrei etnsg   aft stiecuhhattdd  asma thhhocduulrlruebedfn fhtwsaeed, rrauindjleeeind.naoiinnnfeuoutstleeo abwwoieat lhiaeadnnniieerdsn e a  cneoaistdn  dgirrr iluttstei .   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  TLooearg raaaowrnneaionnnneoe mote ,ed.. ,    NcIy   'nfs cwgtaayinons... BS\n",
            "Sboah teermhrocoisnnneeuedr vooie.   LBTorrordbod ,  ISsNeeeonufwae  fwwinwrrioiantns  . SD\n",
            "Hoeaonn doari.n.o  wwaaah   ehcmasslcoehel ddaorr. eutggsl  egltses isnflyeyinnnoutuunrnheeoakdtt .eeltvriiee?r diieodnnnee etysne,oouwsfooinn,dtoeo.    aMstiilrfclt ie imyan nneaeorrnw , asfn IVwhoeaorrrd ie htgolawwo einttnoneed.ld  e \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h7vqctsBGZ_y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}